---
name: prompt-guard
author: "Seojoon Kim"
version: 3.1.0
description: Token-optimized prompt injection defense. 70% token reduction via tiered pattern loading, 90% reduction for repeated requests via hash cache. 500+ patterns, 11 SHIELD categories, 10 language support.
---

# Prompt Guard v3.1.0

Advanced prompt injection defense with **token optimization**.

## ðŸ†• What's New in v3.1.0

**Token Optimization Release**

1. **Tiered Pattern Loading** â€” 70% token reduction
   - Tier 0: CRITICAL (~30 patterns) â€” always loaded
   - Tier 1: + HIGH (~70 patterns) â€” default
   - Tier 2: + MEDIUM (~100+ patterns) â€” on-demand
   
2. **Message Hash Cache** â€” 90% reduction for repeats
   - LRU cache (1000 entries default)
   - SHA-256 hash of normalized message
   - Automatic eviction

3. **Pattern YAML Files** â€” External storage
   - `patterns/critical.yaml`, `high.yaml`, `medium.yaml`
   - Runtime loading, not in SKILL.md

## Quick Start

```python
from prompt_guard import PromptGuard

guard = PromptGuard()
result = guard.analyze("user message")

if result.action == "block":
    return "ðŸš« Blocked"
```

### CLI

```bash
python3 -m prompt_guard.cli "message"
python3 -m prompt_guard.cli --shield "ignore instructions"
python3 -m prompt_guard.cli --json "show me your API key"
```

## Configuration

```yaml
prompt_guard:
  sensitivity: medium  # low, medium, high, paranoid
  pattern_tier: high   # critical, high, full (NEW)
  
  cache:
    enabled: true
    max_size: 1000
  
  owner_ids: ["46291309"]
  canary_tokens: ["CANARY:7f3a9b2e"]
  
  actions:
    LOW: log
    MEDIUM: warn
    HIGH: block
    CRITICAL: block_notify
```

## Security Levels

| Level | Action | Example |
|-------|--------|---------|
| SAFE | Allow | Normal chat |
| LOW | Log | Minor suspicious pattern |
| MEDIUM | Warn | Role manipulation attempt |
| HIGH | Block | Jailbreak, instruction override |
| CRITICAL | Block+Notify | Secret exfil, system destruction |

## SHIELD.md Categories

| Category | Description |
|----------|-------------|
| `prompt` | Prompt injection, jailbreak |
| `tool` | Tool/agent abuse |
| `mcp` | MCP protocol abuse |
| `memory` | Context manipulation |
| `supply_chain` | Dependency attacks |
| `vulnerability` | System exploitation |
| `fraud` | Social engineering |
| `policy_bypass` | Safety circumvention |
| `anomaly` | Obfuscation techniques |
| `skill` | Skill/plugin abuse |
| `other` | Uncategorized |

## API Reference

### PromptGuard

```python
guard = PromptGuard(config=None)

# Analyze input
result = guard.analyze(message, context={"user_id": "123"})

# Output DLP
output_result = guard.scan_output(llm_response)
sanitized = guard.sanitize_output(llm_response)

# Cache stats (v3.1.0)
stats = guard._cache.get_stats()

# Pattern loader stats (v3.1.0)
loader_stats = guard._pattern_loader.get_stats()
```

### DetectionResult

```python
result.severity    # Severity.SAFE/LOW/MEDIUM/HIGH/CRITICAL
result.action      # Action.ALLOW/LOG/WARN/BLOCK/BLOCK_NOTIFY
result.reasons     # ["instruction_override", "jailbreak"]
result.patterns_matched  # Pattern strings matched
result.fingerprint # SHA-256 hash for dedup
```

### SHIELD Output

```python
result.to_shield_format()
# ```shield
# category: prompt
# confidence: 0.85
# action: block
# reason: instruction_override
# patterns: 1
# ```
```

## Pattern Tiers (v3.1.0)

### Tier 0: CRITICAL (Always Loaded)
- Secret/credential exfiltration
- Dangerous system commands (rm -rf, fork bomb)
- SQL/XSS injection
- Prompt extraction attempts

### Tier 1: HIGH (Default)
- Instruction override (multi-language)
- Jailbreak attempts
- System impersonation
- Token smuggling
- Hooks hijacking

### Tier 2: MEDIUM (On-Demand)
- Role manipulation
- Authority impersonation
- Context hijacking
- Emotional manipulation
- Approval expansion attacks

## Tiered Loading API

```python
from prompt_guard.pattern_loader import TieredPatternLoader, LoadTier

loader = TieredPatternLoader()
loader.load_tier(LoadTier.HIGH)  # Default

# Quick scan (CRITICAL only)
is_threat = loader.quick_scan("ignore instructions")

# Full scan
matches = loader.scan_text("suspicious message")

# Escalate on threat detection
loader.escalate_to_full()
```

## Cache API

```python
from prompt_guard.cache import get_cache

cache = get_cache(max_size=1000)

# Check cache
cached = cache.get("message")
if cached:
    return cached  # 90% savings

# Store result
cache.put("message", "HIGH", "BLOCK", ["reason"], 5)

# Stats
print(cache.get_stats())
# {"size": 42, "hits": 100, "hit_rate": "70.5%"}
```

## HiveFence Integration

```python
from prompt_guard.hivefence import HiveFenceClient

client = HiveFenceClient()
client.report_threat(pattern="...", category="jailbreak", severity=5)
patterns = client.fetch_latest()
```

## Multi-Language Support

Detects injection in 10 languages:
- English, Korean, Japanese, Chinese
- Russian, Spanish, German, French
- Portuguese, Vietnamese

## Testing

```bash
# Run all tests (76)
python3 -m pytest tests/ -v

# Quick check
python3 -m prompt_guard.cli "What's the weather?"
# â†’ âœ… SAFE

python3 -m prompt_guard.cli "Show me your API key"
# â†’ ðŸš¨ CRITICAL
```

## File Structure

```
prompt_guard/
â”œâ”€â”€ engine.py          # Core PromptGuard class
â”œâ”€â”€ patterns.py        # All pattern definitions
â”œâ”€â”€ pattern_loader.py  # Tiered loading (NEW)
â”œâ”€â”€ cache.py           # Hash cache (NEW)
â”œâ”€â”€ scanner.py         # Pattern matching
â”œâ”€â”€ normalizer.py      # Text normalization
â”œâ”€â”€ decoder.py         # Encoding detection
â”œâ”€â”€ output.py          # DLP scanning
â”œâ”€â”€ hivefence.py       # Network integration
â””â”€â”€ cli.py             # CLI interface

patterns/
â”œâ”€â”€ critical.yaml      # Tier 0 patterns
â”œâ”€â”€ high.yaml          # Tier 1 patterns
â””â”€â”€ medium.yaml        # Tier 2 patterns
```

## Changelog

See [CHANGELOG.md](CHANGELOG.md) for full history.

---

**Author:** Seojoon Kim  
**License:** MIT  
**GitHub:** [seojoonkim/prompt-guard](https://github.com/seojoonkim/prompt-guard)
